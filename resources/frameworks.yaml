---
#for doc purpose using <placeholder:default_value> syntax when it applies.

# FORMAT:
__dummy_framework_with_defaults:
  version: ''
  module: # defaults to `frameworks.framework_name`
  setup_args: ''
  params: {}
  project: http://url/to/project/repo
  image: # will result in built image `author/image:tag`
    author: automlbenchmark
    image:  # defaults to `framework name to lowercase`
    tag:  # defaults to `framework version`


#########################
### AutoML frameworks ###
#########################

AutoGluon:
  version: "latest"
  description: |
    AutoGluon-Tabular: Unlike existing AutoML frameworks that primarily focus on model/hyperparameter selection,
    AutoGluon-Tabular succeeds by ensembling multiple models and stacking them in multiple layers.
  project: https://auto.gluon.ai
  refs: [https://arxiv.org/abs/2003.06505]
#  params:
#    _save_artifacts: ['leaderboard', 'models', 'info']

##### pretraining framework #####
FTT_pretrain_reconstruction:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_reconstruction_sum"

FTT_pretrain_reconstruction_1:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 1
      max_iter: 2000
      upload_per_n_iter: 1
      folder_name: "pretrain_reconstruction_1_sum"

FTT_pretrain_reconstruction_5:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_reconstruction_5_sum"

FTT_pretrain_reconstruction_10:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 10
      max_iter: 2000
      upload_per_n_iter: 10
      folder_name: "pretrain_reconstruction_10_sum"

FTT_pretrain_supervised:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.objective: None
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_supervised_sum"


FTT_pretrain_supervised_blk_1:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.objective: None
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0
        optimization.patience: 100000

        model.fusion_transformer.n_blocks: 1
        finetune_on: "pretrained_hogwild_block_1.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_supervised_sum_block_1"

FTT_pretrain_supervised_blk_2:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.objective: None
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0
        optimization.patience: 100000

        model.fusion_transformer.n_blocks: 2
        finetune_on: "pretrained_hogwild_block_2.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_supervised_sum_block_2"

FTT_pretrain_supervised_with_cls:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.objective: None
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0
        optimization.patience: 100000

        model.fusion_transformer.share_qv_weights: true
        model.fusion_transformer.n_blocks: 3
        finetune_on: "pretrained_hogwild_with_cls.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_supervised_sum_with_cls"

FTT_pretrain_supervised_only_cls:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.objective: None
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0
        optimization.patience: 100000

        model.fusion_transformer.share_qv_weights: true
        model.fusion_transformer.n_blocks: 0
        finetune_on: "pretrained_hogwild_only_cls.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_supervised_sum_only_cls"

FTT_pretrain_contrastive:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "contrastive"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_contrastive_sum"

FTT_pretrain_all:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 0
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_all_sum"


Fastformer_pretrain_reconstruction:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        model.fusion_transformer.additive_attention: true
        finetune_on: "pretrained_hogwild_Fastformer.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_reconstruction_fastformer"


Saint_pretrain_reconstruction:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrained_hogwild_Saint.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_reconstruction_saint"


##### light finetuning #####
FTT_ft0:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_1_sum/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft250:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128

        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_1_sum/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft500:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_1_sum/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft1000:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_1_sum/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


FTT_ft1500:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_1_sum/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


FTT_ft2000:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_1_sum/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


##### light finetuning  #####
FTT_ft0_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_10_sum/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft250_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128

        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_10_sum/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft500_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128

        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_10_sum/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft1000_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_10_sum/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft1500_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_10_sum/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


FTT_ft2000_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_10_sum/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


##### fewshot ##### 
FTT_ft0_fewshot:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_5_sum/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft250_fewshot:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128

        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_5_sum/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft500_fewshot:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_5_sum/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft1000_fewshot:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_5_sum/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft1500_fewshot:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_5_sum/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft2000_fewshot:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_5_sum/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


##### fewshot ##### 
FTT_ft0_fewshot_1k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.25
    holdout_frac: 0.125

FTT_ft250_fewshot_1k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128

        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.25
    holdout_frac: 0.125

FTT_ft500_fewshot_1k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.25
    holdout_frac: 0.125

FTT_ft1000_fewshot_1k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.25
    holdout_frac: 0.125

FTT_ft1500_fewshot_1k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.25
    holdout_frac: 0.125

FTT_ft2000_fewshot_1k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.25
    holdout_frac: 0.125

##### fewshot ##### 
FTT_ft0_fewshot_2k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.5
    holdout_frac: 0.125

FTT_ft250_fewshot_2k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128

        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.5
    holdout_frac: 0.125

FTT_ft500_fewshot_2k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.5
    holdout_frac: 0.125

FTT_ft1000_fewshot_2k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.5
    holdout_frac: 0.125

FTT_ft1500_fewshot_2k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.5
    holdout_frac: 0.125

FTT_ft2000_fewshot_2k:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_reconstruction_sum/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
      few_shot: 0.5
    holdout_frac: 0.125

##### heavy finetuning contrastive #####
FTT_ft0_cont:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_contrastive_sum/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft250_cont:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128

        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_contrastive_sum/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft500_cont:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_contrastive_sum/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

FTT_ft1000_cont:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_contrastive_sum/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


FTT_ft1500_cont:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_contrastive_sum/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


FTT_ft2000_cont:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        # optimization.patience: 3
        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        finetune_on: "pretrain_contrastive_sum/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125



## Saint
Saint_ft0:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.patience: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft250:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.patience: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft500:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.patience: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft1000:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.patience: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft1500:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.patience: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft2000:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.patience: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

##### light finetuning  #####
Saint_ft0_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_0/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft250_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_250/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft500_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft1000_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_1000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft1500_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_1500/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125

Saint_ft2000_light:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        pretrainer: true
        pretrainer.start_pretrain_coefficient: 0
        pretrainer.end_pretrain_coefficient: 0
        pretrainer.pretrain_epochs: 0

        optimization.max_epochs: 3
        optimization.top_k: 1
        optimization.val_check_interval: 1.0

        model.fusion_transformer.row_attention: true
        model.fusion_transformer.row_attention_layer: "shared"
        optimization.row_attention_weight_decay: 0.1
        finetune_on: "pretrain_reconstruction_saint/iter_2000/pretrained.ckpt"
    is_pretrain:
      is_pretrain: false
    holdout_frac: 0.125


## 
FTT_pretrain_reconstruction_18_task:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 18
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_reconstruction_sum_18_task"

FTT_pretrain_reconstruction_36_task:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 36
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_reconstruction_sum_36_tasks"

FTT_pretrain_reconstruction_52_task:
  extends: AutoGluon
  version: "latest_gpu"
  params:
    hyperparameters:
      FT_TRANSFORMER:
        env.per_gpu_batch_size: 128
        optimization.max_epochs: 100000

        pretrainer: true
        pretrainer.augmentation_type: "permutation"
        pretrainer.corruption_rate: 0.6
        pretrainer.objective: "reconstruction"
        pretrainer.start_pretrain_coefficient: 1
        pretrainer.end_pretrain_coefficient: 1
        pretrainer.decay_pretrain_coefficient: 1
        pretrainer.pretrain_epochs: 100000
        optimization.patience: 100000

        finetune_on: "pretrained_hogwild.ckpt"
    is_pretrain:
      is_pretrain: true
      name: true
      num_tasks: 52
      iter_per_save: 5
      max_iter: 2000
      upload_per_n_iter: 5
      folder_name: "pretrain_reconstruction_sum_36_tasks"